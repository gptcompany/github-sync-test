#!/usr/bin/env python3
"""Unified tasks.md <-> GitHub Issues management.

Features:
- Create GitHub issues from tasks.md with milestones
- Link issues to GitHub ProjectV2 boards (GraphQL API)
- Bidirectional sync (completed tasks <-> closed issues)
- Auto-create labels and projects if missing

Usage:
    # Create issues from tasks.md
    python taskstoissues.py --tasks-file specs/034/tasks.md

    # Create issues and link to Project board (explicit name)
    python taskstoissues.py --tasks-file specs/034/tasks.md --project "My Project Board"

    # Create issues and link to auto-derived Project board ("{repo_name} Development")
    python taskstoissues.py --tasks-file specs/034/tasks.md --auto-project

    # Auto-create project if it doesn't exist
    python taskstoissues.py --tasks-file specs/034/tasks.md --auto-project --create-project

    # Bidirectional sync (close issues for [X] tasks, mark [X] for closed issues)
    python taskstoissues.py --sync specs/034

    # Sync all specs
    python taskstoissues.py --sync-all

    # Dry run (preview without changes)
    python taskstoissues.py --tasks-file specs/034/tasks.md --dry-run
    python taskstoissues.py --sync specs/034 --dry-run
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path

# Import shared functions from github_sync_core
try:
    from github_sync_core import (
        STANDARD_LABELS,
        run_gh_command,
        get_repo_info,
        ensure_labels_exist,
        ensure_project_exists,
        add_issue_to_project,
        get_issue_node_id,
        get_existing_milestones,
        get_existing_issues as core_get_existing_issues,
    )
except ImportError:
    # Fallback for standalone usage - define minimal versions
    import subprocess

    STANDARD_LABELS = {
        "priority-p1": {"color": "b60205", "description": "High priority task"},
        "priority-p2": {"color": "fbca04", "description": "Medium priority task"},
        "priority-p3": {"color": "0e8a16", "description": "Low priority task"},
        "auto-generated": {
            "color": "c5def5",
            "description": "Auto-generated by SpecKit",
        },
        "parallelizable": {
            "color": "5319e7",
            "description": "Can be worked on in parallel",
        },
        "evolve": {"color": "bfdadc", "description": "Evolving/experimental task"},
    }

    def run_gh_command(args: list[str], check: bool = True) -> tuple[int, str, str]:
        try:
            result = subprocess.run(
                ["gh"] + args, capture_output=True, text=True, check=check
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.CalledProcessError as e:
            return e.returncode, e.stdout, e.stderr
        except FileNotFoundError:
            return 1, "", "gh CLI not found"

    def get_repo_info() -> tuple[str, str] | None:
        code, stdout, _ = run_gh_command(
            ["repo", "view", "--json", "owner,name", "-q", ".owner.login,.name"],
            check=False,
        )
        if code != 0 or not stdout:
            return None
        parts = stdout.strip().split("\n")
        return (parts[0], parts[1]) if len(parts) >= 2 else None

    def ensure_labels_exist(labels: list[str], dry_run: bool = False) -> list[str]:
        return []  # Fallback does nothing

    def ensure_project_exists(owner: str, name: str, dry_run: bool = False):
        return None

    def add_issue_to_project(
        project_id: str, issue_id: str, dry_run: bool = False
    ) -> str | None:
        return None

    def get_issue_node_id(issue_number: int) -> str | None:
        code, stdout, _ = run_gh_command(
            ["issue", "view", str(issue_number), "--json", "id", "-q", ".id"],
            check=False,
        )
        return stdout.strip() if code == 0 and stdout else None

    def get_existing_milestones() -> dict[str, int]:
        return {}

    def core_get_existing_issues(label_filter: str | None = None) -> dict[str, dict]:
        return {}

# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class Task:
    """Represents a single task from tasks.md."""

    id: str
    story: str
    description: str
    status: str  # "pending" or "completed"
    priority: str = "P2"
    markers: list[str] = field(default_factory=list)
    files: list[str] = field(default_factory=list)
    line_number: int = 0
    line_text: str = ""  # Original line for sync


@dataclass
class UserStory:
    """Represents a user story section."""

    id: str
    title: str
    description: str
    tasks: list[Task] = field(default_factory=list)


@dataclass
class SyncResult:
    """Results from sync operation."""

    milestones_created: int = 0
    milestones_existing: int = 0
    issues_created: int = 0
    issues_existing: int = 0
    issues_closed: int = 0
    tasks_marked_complete: int = 0
    errors: list[str] = field(default_factory=list)


# =============================================================================
# Local Helpers
# =============================================================================


def get_default_project_name() -> str | None:
    """Get default project board name based on repo name."""
    repo_info = get_repo_info()
    if repo_info:
        _, repo_name = repo_info
        return f"{repo_name} Development"
    return None


def get_existing_issues(spec_label: str | None = None) -> dict[str, dict]:
    """Get existing issues with task IDs in title."""
    query = "is:issue"
    if spec_label:
        query += f" label:{spec_label}"

    code, stdout, _ = run_gh_command(
        [
            "issue",
            "list",
            "--search",
            query,
            "--state",
            "all",
            "--limit",
            "500",
            "--json",
            "number,title,state,id",
        ],
        check=False,
    )
    if code != 0:
        return {}

    issues = {}
    try:
        data = json.loads(stdout) if stdout else []
        for issue in data:
            match = re.search(r"(T\d+)", issue.get("title", ""))
            if match:
                issues[match.group(1)] = {
                    "number": issue["number"],
                    "state": issue["state"],
                    "title": issue["title"],
                    "node_id": issue.get("id"),
                }
    except json.JSONDecodeError:
        pass
    return issues


# =============================================================================
# Parsing
# =============================================================================


def parse_tasks_file(file_path: Path) -> tuple[list[UserStory], list[Task]]:
    """Parse tasks.md and extract user stories and tasks."""
    content = file_path.read_text()
    lines = content.split("\n")

    user_stories: list[UserStory] = []
    all_tasks: list[Task] = []
    current_story: UserStory | None = None

    story_pattern = re.compile(r"^###?\s*(US\d+)[:\s]+(.+)$")
    task_pattern = re.compile(
        r"^\s*-\s*\[([ xX])\]\s*(T\d+)\s*(\[US\d+\])?\s*((?:\[[^\]]+\]\s*)*)\s*(.+)$"
    )
    file_pattern = re.compile(r"^\s+-\s*File:\s*`(.+)`$")

    for i, line in enumerate(lines, 1):
        story_match = story_pattern.match(line)
        if story_match:
            story_id = story_match.group(1)
            story_title = story_match.group(2).strip()
            description = ""
            for j in range(i, min(i + 5, len(lines))):
                next_line = lines[j].strip()
                if (
                    next_line
                    and not next_line.startswith("#")
                    and not next_line.startswith("-")
                ):
                    description = next_line
                    break
            current_story = UserStory(
                id=story_id, title=story_title, description=description
            )
            user_stories.append(current_story)
            continue

        task_match = task_pattern.match(line)
        if task_match:
            status = "completed" if task_match.group(1).upper() == "X" else "pending"
            task_id = task_match.group(2)
            story_ref = task_match.group(3) or ""
            markers_str = task_match.group(4) or ""
            description = task_match.group(5).strip()

            markers = re.findall(r"\[([^\]]+)\]", markers_str)
            priority = "P2"
            for marker in markers:
                if marker.startswith("P") and marker[1:].isdigit():
                    priority = marker
                    break

            story_id = ""
            if story_ref:
                story_id = story_ref.strip("[]")
            elif current_story:
                story_id = current_story.id

            task = Task(
                id=task_id,
                story=story_id,
                description=description,
                status=status,
                priority=priority,
                markers=markers,
                line_number=i,
                line_text=line,
            )
            all_tasks.append(task)
            if current_story:
                current_story.tasks.append(task)
            continue

        file_match = file_pattern.match(line)
        if file_match and all_tasks:
            all_tasks[-1].files.append(file_match.group(1))

    return user_stories, all_tasks


# =============================================================================
# Issue Creation
# =============================================================================


def create_milestone(
    story: UserStory, spec_dir: str, dry_run: bool = False
) -> int | None:
    """Create a GitHub milestone for a user story."""
    title = f"{story.id}: {story.title}"
    description = f"{story.description}\n\nSpec: {spec_dir}"

    if dry_run:
        print(f"[DRY RUN] Would create milestone: {title}")
        return None

    code, stdout, _ = run_gh_command(
        [
            "api",
            "repos/{owner}/{repo}/milestones",
            "--method",
            "POST",
            "-f",
            f"title={title}",
            "-f",
            "state=open",
            "-f",
            f"description={description}",
            "-q",
            ".number",
        ],
        check=False,
    )
    return int(stdout.strip()) if code == 0 and stdout else None


def create_issue(
    task: Task,
    spec_dir: str,
    milestone_title: str | None,
    spec_label: str | None,
    project_id: str | None = None,
    dry_run: bool = False,
) -> int | None:
    """Create a GitHub issue for a task.

    Args:
        task: Task object with details
        spec_dir: Spec directory path
        milestone_title: Milestone title to assign (gh cli expects title not number)
        spec_label: Spec-specific label to add
        project_id: GraphQL node ID of ProjectV2 to link to
        dry_run: If True, don't actually create
    """
    title = f"[{task.id}] {task.description}"

    body_parts = [
        "## Task Details",
        "",
        f"**Task ID**: {task.id}",
        f"**User Story**: {task.story}",
        f"**Priority**: {task.priority}",
        "",
    ]
    if task.markers:
        body_parts.extend([f"**Markers**: {', '.join(task.markers)}", ""])
    if task.files:
        body_parts.append("### Files")
        body_parts.extend([f"- `{f}`" for f in task.files])
        body_parts.append("")
    body_parts.extend(
        [
            "### Source",
            f"- Spec: `{spec_dir}/spec.md`",
            f"- Tasks: `{spec_dir}/tasks.md` (line {task.line_number})",
            "",
            "---",
            "*Auto-generated by SpecKit pipeline*",
        ]
    )
    body = "\n".join(body_parts)

    labels = ["auto-generated", f"priority-{task.priority.lower()}"]
    if spec_label:
        labels.append(spec_label)
    if "E" in task.markers:
        labels.append("evolve")
    if "P" in task.markers:
        labels.append("parallelizable")

    if dry_run:
        print(f"[DRY RUN] Would create issue: {title}")
        if project_id:
            print("[DRY RUN] Would link to project")
        return None

    # Create the issue without --project flag (deprecated)
    cmd = ["issue", "create", "--title", title, "--body", body]
    for label in labels:
        cmd.extend(["--label", label])
    if milestone_title:
        cmd.extend(["--milestone", milestone_title])

    code, stdout, stderr = run_gh_command(cmd, check=False)
    if code != 0:
        print(f"Failed to create issue for {task.id}: {stderr}")
        return None

    match = re.search(r"/issues/(\d+)", stdout)
    if not match:
        return None

    issue_num = int(match.group(1))

    # Link to project using GraphQL API (ProjectsV2)
    if project_id:
        issue_node_id = get_issue_node_id(issue_num)
        if issue_node_id:
            item_id = add_issue_to_project(project_id, issue_node_id, dry_run)
            if item_id:
                print("  Linked to project")

    return issue_num


# =============================================================================
# Sync Operations
# =============================================================================


def sync_create_issues(
    stories: list[UserStory],
    tasks: list[Task],
    spec_dir: str,
    project_name: str | None = None,
    create_project: bool = False,
    dry_run: bool = False,
) -> SyncResult:
    """Create issues for pending tasks.

    Args:
        stories: User stories from tasks.md
        tasks: Tasks from tasks.md
        spec_dir: Spec directory path
        project_name: Project board name to link issues to
        create_project: If True, create project if it doesn't exist
        dry_run: If True, don't actually create
    """
    result = SyncResult()

    # Extract spec label from dir
    spec_match = re.search(r"(\d{3})-", spec_dir)
    spec_label = f"spec-{spec_match.group(1)}" if spec_match else None

    # Collect all labels that will be needed
    needed_labels: set[str] = {"auto-generated"}
    if spec_label:
        needed_labels.add(spec_label)
    for task in tasks:
        if task.status == "completed":
            continue
        needed_labels.add(f"priority-{task.priority.lower()}")
        if "E" in task.markers:
            needed_labels.add("evolve")
        if "P" in task.markers:
            needed_labels.add("parallelizable")

    # Ensure all labels exist before creating issues
    if needed_labels:
        print(f"Checking {len(needed_labels)} labels...")
        ensure_labels_exist(list(needed_labels), dry_run)
        print()

    # Resolve project name to project ID via GraphQL
    project_id: str | None = None
    if project_name:
        repo_info = get_repo_info()
        if repo_info:
            owner, _ = repo_info
            if create_project:
                project_info = ensure_project_exists(owner, project_name, dry_run)
            else:
                # Import here to avoid circular dependency
                try:
                    from github_sync_core import get_project_by_name

                    project_info = get_project_by_name(owner, project_name)
                except ImportError:
                    project_info = None

            if project_info:
                project_id = project_info.id
                print(f"Project: {project_info.title} (#{project_info.number})\n")
            elif not dry_run:
                print(
                    f"Warning: Project '{project_name}' not found. Use --create-project to create it.\n"
                )
        else:
            print(
                "Warning: Could not determine repository owner. Project linking disabled.\n"
            )

    existing_milestones = get_existing_milestones()
    existing_issues = get_existing_issues(spec_label)
    # Map story.id -> milestone TITLE (gh cli requires title, not number)
    milestone_map: dict[str, str | None] = {}

    # Create milestones
    for story in stories:
        milestone_title = f"{story.id}: {story.title}"
        if milestone_title in existing_milestones:
            milestone_map[story.id] = milestone_title  # Store title, not number
            result.milestones_existing += 1
            print(f"Milestone exists: {milestone_title}")
        else:
            milestone_num = create_milestone(story, spec_dir, dry_run)
            if milestone_num or dry_run:
                milestone_map[story.id] = milestone_title  # Store title
                result.milestones_created += 1
                print(f"Created milestone: {milestone_title}")

    # Create issues
    for task in tasks:
        if task.status == "completed":
            continue
        if task.id in existing_issues:
            result.issues_existing += 1
            print(f"Issue exists for {task.id}: #{existing_issues[task.id]['number']}")
            continue

        milestone_title = milestone_map.get(task.story)
        issue_num = create_issue(
            task, spec_dir, milestone_title, spec_label, project_id, dry_run
        )
        if issue_num or dry_run:
            result.issues_created += 1
            print(f"Created issue for {task.id}: #{issue_num}")

    return result


def sync_bidirectional(spec_dir: Path, dry_run: bool = False) -> SyncResult:
    """Bidirectional sync: completed tasks <-> closed issues."""
    result = SyncResult()
    tasks_path = spec_dir / "tasks.md"

    if not tasks_path.exists():
        result.errors.append(f"No tasks.md in {spec_dir}")
        return result

    # Get spec label
    spec_match = re.search(r"(\d{3})-", spec_dir.name)
    spec_label = f"spec-{spec_match.group(1)}" if spec_match else None

    # Parse tasks and get issues
    _, tasks = parse_tasks_file(tasks_path)
    existing_issues = get_existing_issues(spec_label)

    # Build lookup
    tasks_by_id = {t.id: t for t in tasks}

    # Completed tasks -> Close issues
    for task in tasks:
        if task.status == "completed" and task.id in existing_issues:
            issue = existing_issues[task.id]
            if issue["state"] == "OPEN":
                if not dry_run:
                    run_gh_command(
                        ["issue", "close", str(issue["number"])], check=False
                    )
                result.issues_closed += 1
                print(f"Closed issue #{issue['number']} ({task.id})")

    # Closed issues -> Mark tasks [X]
    content = tasks_path.read_text()
    modified = False

    for task_id, issue in existing_issues.items():
        if issue["state"] == "CLOSED" and task_id in tasks_by_id:
            task = tasks_by_id[task_id]
            if task.status != "completed":
                old_line = task.line_text
                new_line = old_line.replace("- [ ]", "- [X]", 1)
                if old_line in content:
                    content = content.replace(old_line, new_line)
                    result.tasks_marked_complete += 1
                    modified = True
                    print(f"Marked [X]: {task_id}")

    if modified and not dry_run:
        tasks_path.write_text(content)

    return result


# =============================================================================
# Main
# =============================================================================


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Unified tasks.md <-> GitHub Issues management",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Create issues from tasks.md
  python taskstoissues.py --tasks-file specs/034/tasks.md

  # Create issues and link to auto-derived project board
  python taskstoissues.py --tasks-file specs/034/tasks.md --auto-project

  # Create project if missing, then link issues
  python taskstoissues.py --tasks-file specs/034/tasks.md --auto-project --create-project

  # Bidirectional sync for a spec
  python taskstoissues.py --sync specs/034-kelly-criterion

  # Sync all specs in specs/ directory
  python taskstoissues.py --sync-all

  # Preview changes
  python taskstoissues.py --tasks-file specs/034/tasks.md --dry-run
        """,
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--tasks-file", type=Path, help="Create issues from tasks.md file"
    )
    group.add_argument(
        "--sync", type=Path, help="Bidirectional sync for spec directory"
    )
    group.add_argument(
        "--sync-all", action="store_true", help="Sync all specs in specs/"
    )

    parser.add_argument(
        "--spec-dir", type=str, help="Spec directory (defaults to tasks-file parent)"
    )
    parser.add_argument(
        "--project",
        type=str,
        help="GitHub Project board to link issues to (e.g., 'nautilus_dev Development')",
    )
    parser.add_argument(
        "--auto-project",
        action="store_true",
        help="Auto-derive project name from repo ('{repo_name} Development')",
    )
    parser.add_argument(
        "--create-project",
        action="store_true",
        help="Create the project board if it doesn't exist (requires --project or --auto-project)",
    )
    parser.add_argument(
        "--dry-run", action="store_true", help="Preview without changes"
    )
    parser.add_argument("--output-json", type=Path, help="Write results to JSON file")

    args = parser.parse_args()

    # Resolve project name
    project_name = args.project
    if args.auto_project and not project_name:
        project_name = get_default_project_name()
        if not project_name:
            print("Warning: Could not auto-detect project name (not in a git repo?)")

    result = SyncResult()

    if args.tasks_file:
        # Create issues mode
        if not args.tasks_file.exists():
            print(f"Error: tasks file not found: {args.tasks_file}")
            sys.exit(1)

        spec_dir = args.spec_dir or str(args.tasks_file.parent)
        print(f"Creating issues from: {args.tasks_file}")
        print(f"Spec dir: {spec_dir}")
        print(f"Dry run: {args.dry_run}\n")

        stories, tasks = parse_tasks_file(args.tasks_file)
        print(f"Found {len(stories)} user stories and {len(tasks)} tasks\n")
        if project_name:
            print(f"Project board: {project_name}")
            if args.create_project:
                print("  (will create if missing)")
            print()
        result = sync_create_issues(
            stories, tasks, spec_dir, project_name, args.create_project, args.dry_run
        )

    elif args.sync:
        # Bidirectional sync mode
        if not args.sync.exists():
            print(f"Error: spec directory not found: {args.sync}")
            sys.exit(1)

        print(f"Bidirectional sync: {args.sync}")
        print(f"Dry run: {args.dry_run}\n")
        result = sync_bidirectional(args.sync, args.dry_run)

    elif args.sync_all:
        # Sync all specs
        specs_dir = Path("specs")
        if not specs_dir.exists():
            print("Error: specs/ directory not found")
            sys.exit(1)

        spec_dirs = [
            d for d in specs_dir.iterdir() if d.is_dir() and re.match(r"\d{3}-", d.name)
        ]

        print(
            f"{'[DRY RUN] ' if args.dry_run else ''}Syncing {len(spec_dirs)} specs...\n"
        )

        for spec_dir in sorted(spec_dirs):
            print(f"\n### {spec_dir.name}")
            r = sync_bidirectional(spec_dir, args.dry_run)
            result.issues_closed += r.issues_closed
            result.tasks_marked_complete += r.tasks_marked_complete
            result.errors.extend(r.errors)

    # Print summary
    print("\n=== Summary ===")
    if args.tasks_file:
        print(f"Milestones created: {result.milestones_created}")
        print(f"Milestones existing: {result.milestones_existing}")
        print(f"Issues created: {result.issues_created}")
        print(f"Issues existing: {result.issues_existing}")
    else:
        print(f"Issues closed: {result.issues_closed}")
        print(f"Tasks marked [X]: {result.tasks_marked_complete}")

    if result.errors:
        print(f"Errors: {len(result.errors)}")
        for err in result.errors:
            print(f"  - {err}")

    if args.dry_run:
        print("\n[DRY RUN] No changes applied.")

    # JSON output
    if args.output_json:
        output = {
            "milestones_created": result.milestones_created,
            "milestones_existing": result.milestones_existing,
            "issues_created": result.issues_created,
            "issues_existing": result.issues_existing,
            "issues_closed": result.issues_closed,
            "tasks_marked_complete": result.tasks_marked_complete,
            "errors": result.errors,
        }
        args.output_json.parent.mkdir(parents=True, exist_ok=True)
        args.output_json.write_text(json.dumps(output, indent=2))
        print(f"\nResults: {args.output_json}")


if __name__ == "__main__":
    main()
